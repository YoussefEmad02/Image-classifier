{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj94ejpm6mFq",
        "outputId": "f71bc5cf-8296-438a-9be7-f2f418418a4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzmxvFLL62Lc",
        "outputId": "ff81d525-233b-4375-fa55-ada0ecd328d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5753Opj62M2"
      },
      "outputs": [],
      "source": [
        "import splitfolders\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms  \n",
        "import torchvision\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torchvision.transforms as transforms \n",
        "from torchvision.transforms import ToTensor,Normalize, RandomHorizontalFlip, Resize\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMXmqHOs62Rp"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/MyDrive/Scenes training set'\n",
        "#splitfolders.ratio(base_dir , output=\"/content/drive/MyDrive/output\", seed=1337, ratio=(.7, 0.3)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smapzE3g62TF",
        "outputId": "e6e76b39-b3ca-4792-9424-3edfac4f21d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['buildings', 'street', 'forest', 'mountain', 'sea', 'glacier']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data_dir_Train = '/content/drive/MyDrive/output/train'\n",
        "data_dir_Test = '/content/drive/MyDrive/output/val'\n",
        "data_dir_pred = '/content/drive/MyDrive/testing/Scenes testing test'\n",
        "\n",
        "train_dir = data_dir_Train \n",
        "valid_dir = data_dir_Test \n",
        "pred_files = [os.path.join(data_dir_pred, f) for f in os.listdir(data_dir_pred)]\n",
        "\n",
        "outcomes = os.listdir(train_dir)\n",
        "outcomes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VlqjP7B-kbA"
      },
      "source": [
        "Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WxMvCgt-l2C"
      },
      "outputs": [],
      "source": [
        "# convert data to a normalized torch.FloatTensor\n",
        "transform = torchvision.transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # randomly flip and rotate\n",
        "    transforms.ColorJitter(0.3,0.4,0.4,0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.425, 0.415, 0.405), (0.205, 0.205, 0.205))\n",
        "    ])\n",
        "\n",
        "# Augmentation on test images not needed\n",
        "transform_tests = torchvision.transforms.Compose([\n",
        "    transforms.Resize((150,150)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.425, 0.415, 0.405), (0.255, 0.245, 0.235))\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ebkOAY1-l3i"
      },
      "outputs": [],
      "source": [
        "train_data = torchvision.datasets.ImageFolder(root=train_dir,transform=transform)\n",
        "test_data = torchvision.datasets.ImageFolder(root=valid_dir,transform=transform_tests)\n",
        "\n",
        "\n",
        "valid_size = 0.15\n",
        "# Splot data into train and validation set\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brigt-Dg-l7N",
        "outputId": "6e5d1404-c980-4ca6-ca23-f63fe2cfb5e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_data,batch_size=50,sampler=train_sampler,num_workers=2)\n",
        "valid_loader = DataLoader(train_data, batch_size =100, sampler=valid_sampler, num_workers=3)\n",
        "test_loader= DataLoader(test_data,batch_size=32,shuffle=False,num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwq_KtWpAscb"
      },
      "outputs": [],
      "source": [
        "# check if cuda is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "device =  torch.device('cuda' if torch.cuda.is_available else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB5MqTxbAzvi"
      },
      "source": [
        "Using pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c6cebea7927247c7a7810fbd4dc18748",
            "500ada35ddb54db0878d5e79a6e1fdca",
            "815507206c9d48b09655ad50ed4d0a26",
            "ae6ab078c3784961829fe8902c3b84d6",
            "8bbebff1a38140f29249d6ec768b9043",
            "5f8f0d57db274d3281daa344b6b628e2",
            "67ea083248d74551a4bd99ec1885f119",
            "f1a083f3be284b4aa2874f06870d7a7d",
            "62be2dbb21464674a0189e7091f0b465",
            "d7569c4672bc4979916eb2b65970d5af",
            "ebe8fb7164824f9f8ad03749eac2e352"
          ]
        },
        "id": "g5pi3D26Aw7r",
        "outputId": "cd11cf0f-ed79-4168-b307-510efca46769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6cebea7927247c7a7810fbd4dc18748"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): ReLU(inplace=True)\n",
              "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (33): ReLU(inplace=True)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=4096, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import torchvision\n",
        "model = torchvision.models.vgg19(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.required_grad = False\n",
        "\n",
        "\n",
        "num_ftrt = model.classifier[-1].in_features\n",
        "\n",
        "model.fc = nn.Linear(num_ftrt,6)\n",
        "model.to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTWBbVAvAxPE"
      },
      "outputs": [],
      "source": [
        "# Specify loss function and optimizer\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,6], gamma=0.06)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuqPgoOGBJbu"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3ICEcLDBGDA",
        "outputId": "f213ca5b-286f-4ba1-99f0-429a008f9d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \t Training Loss: 1.394 \t Validation Loss: 0.488\n",
            "Validation loss decreased inf--->0.4881  Saving model...\n",
            "Learning Rate ------------->0.0010\n",
            "Epoch: 2 \t Training Loss: 0.460 \t Validation Loss: 0.378\n",
            "Validation loss decreased 0.4881--->0.3781  Saving model...\n",
            "Learning Rate ------------->0.0010\n",
            "Epoch: 3 \t Training Loss: 0.366 \t Validation Loss: 0.319\n",
            "Validation loss decreased 0.3781--->0.3191  Saving model...\n",
            "Learning Rate ------------->0.0010\n",
            "Epoch: 4 \t Training Loss: 0.331 \t Validation Loss: 0.290\n",
            "Validation loss decreased 0.3191--->0.2904  Saving model...\n",
            "Learning Rate ------------->0.0001\n",
            "Epoch: 5 \t Training Loss: 0.291 \t Validation Loss: 0.283\n",
            "Validation loss decreased 0.2904--->0.2826  Saving model...\n",
            "Learning Rate ------------->0.0001\n",
            "Epoch: 6 \t Training Loss: 0.282 \t Validation Loss: 0.282\n",
            "Validation loss decreased 0.2826--->0.2819  Saving model...\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 7 \t Training Loss: 0.280 \t Validation Loss: 0.284\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 8 \t Training Loss: 0.281 \t Validation Loss: 0.288\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 9 \t Training Loss: 0.283 \t Validation Loss: 0.292\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 10 \t Training Loss: 0.290 \t Validation Loss: 0.274\n",
            "Validation loss decreased 0.2819--->0.2738  Saving model...\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 11 \t Training Loss: 0.284 \t Validation Loss: 0.284\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 12 \t Training Loss: 0.280 \t Validation Loss: 0.276\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 13 \t Training Loss: 0.280 \t Validation Loss: 0.276\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 14 \t Training Loss: 0.280 \t Validation Loss: 0.276\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 15 \t Training Loss: 0.282 \t Validation Loss: 0.285\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 16 \t Training Loss: 0.287 \t Validation Loss: 0.289\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 17 \t Training Loss: 0.288 \t Validation Loss: 0.276\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 18 \t Training Loss: 0.284 \t Validation Loss: 0.282\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 19 \t Training Loss: 0.284 \t Validation Loss: 0.286\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 20 \t Training Loss: 0.280 \t Validation Loss: 0.291\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 21 \t Training Loss: 0.285 \t Validation Loss: 0.286\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 22 \t Training Loss: 0.280 \t Validation Loss: 0.280\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 23 \t Training Loss: 0.287 \t Validation Loss: 0.281\n",
            "Learning Rate ------------->0.0000\n",
            "Epoch: 24 \t Training Loss: 0.273 \t Validation Loss: 0.286\n",
            "Learning Rate ------------->0.0000\n"
          ]
        }
      ],
      "source": [
        "# number of epochs for training set\n",
        "epochs = 24\n",
        "\n",
        "# track change in validation loss\n",
        "valid_loss_min = np.Inf\n",
        "val_loss = []\n",
        "tn_loss = []\n",
        "for epoch in range(1,epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    # Train the model\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):       \n",
        "        # move tensor to gpu if cuda is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "        # clear the gradiant of all optimizer variable\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute pradictions by passing inputs\n",
        "        output = model(data)\n",
        "        # calculate batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradiant of the loss with respect to the parameters\n",
        "        loss.backward()\n",
        "        # update parameters by optimizing single step\n",
        "        optimizer.step()\n",
        "        \n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "    # validate the model\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "        # move tensor to gpu\n",
        "        if train_on_gpu:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "        # forward pass: compute the validation predictions\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update the validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average loss\n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "    val_loss.append(valid_loss)\n",
        "    tn_loss.append(train_loss)\n",
        "    # update learning rate\n",
        "    scheduler.step()\n",
        "    # Print the train and validation loss statistic\n",
        "    print('Epoch: {} \\t Training Loss: {:.3f} \\t Validation Loss: {:.3f}'.format(epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss decrease\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print(\"Validation loss decreased {:.4f}--->{:.4f}  Saving model...\".format(valid_loss_min, valid_loss))\n",
        "        # save current model\n",
        "        torch.save(model.state_dict(), 'model_state.pt')\n",
        "        valid_loss_min = valid_loss\n",
        "    print('Learning Rate ------------->{:.4f}'.format(optimizer.state_dict()['param_groups'][0]['lr']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW9CJ06jBafR"
      },
      "source": [
        "Load saved parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm1O3FAyBGEw",
        "outputId": "296e3f58-ef9f-4dcf-d433-5825c79b28c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): ReLU(inplace=True)\n",
              "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (33): ReLU(inplace=True)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=4096, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Load model state dict\n",
        "model.load_state_dict(torch.load('model_state.pt'))\n",
        "model.eval()\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yXT6EpxEDRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a939a42-77b7-4625-ba75-b963608888b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images Tested= 2810\n",
            "\n",
            " Model Accuracy= 90.2846975088968\n"
          ]
        }
      ],
      "source": [
        "correct_count, all_count = 0,0\n",
        "for images, labels in test_loader:\n",
        "    for i in range(len(labels)):\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "        img = images[i].view(1,3,150,150)\n",
        "        with torch.no_grad():\n",
        "            logps = model(img)\n",
        "            \n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.cpu()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.cpu()[i]\n",
        "        if(true_label == pred_label):\n",
        "            correct_count += 1\n",
        "        all_count += 1\n",
        "        \n",
        "print(\"Number of images Tested=\", all_count)\n",
        "print(\"\\n Model Accuracy=\",(correct_count/all_count)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mcmpk7-EnGp"
      },
      "source": [
        "Image Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jM0n20_nEDTK"
      },
      "outputs": [],
      "source": [
        "def pred_class(img):\n",
        "    # transform images\n",
        "    img_tens = transform_tests(img)\n",
        "    # change image format (3,150,150) to (1,3,150,150) by help of unsqueeze function\n",
        "    # image needs to be in cuda before predition\n",
        "    img_im = img_tens.unsqueeze(0).cuda() \n",
        "    uinput = Variable(img_im)\n",
        "    uinput = uinput.to(device)\n",
        "    out = model(uinput)\n",
        "    # convert image to numpy format in cpu and snatching max prediction score class index\n",
        "    index = out.data.cpu().numpy().argmax()    \n",
        "    return index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs8TgSEZEx5D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "791d3e58-450b-4c39-d7c4-ff13e03f80fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# make class dictionary so i can grab class name by index(key)\n",
        "classes = {k:v for k , v in enumerate(sorted(outcomes))}\n",
        "model.eval()\n",
        "\n",
        "predictions=[]\n",
        "plt.figure(figsize=(20,20))\n",
        "for i, images in enumerate(pred_files):\n",
        "    # just want 25 images to print\n",
        "    img = Image.open(images)\n",
        "    index = pred_class(img)\n",
        "    predictions.append(index)\n",
        "\n",
        "    \n",
        "  \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEhenjlFOoX4"
      },
      "outputs": [],
      "source": [
        "name_image=os.listdir(data_dir_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LolnULpFEvx"
      },
      "outputs": [],
      "source": [
        "data={'Image':name_image,'Label':predictions}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N1qaEfTRLTy"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data, columns =['Image','Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYNXPdS_Rjg-"
      },
      "outputs": [],
      "source": [
        "df.to_csv('/content/drive/MyDrive/vgg19.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6cebea7927247c7a7810fbd4dc18748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_500ada35ddb54db0878d5e79a6e1fdca",
              "IPY_MODEL_815507206c9d48b09655ad50ed4d0a26",
              "IPY_MODEL_ae6ab078c3784961829fe8902c3b84d6"
            ],
            "layout": "IPY_MODEL_8bbebff1a38140f29249d6ec768b9043"
          }
        },
        "500ada35ddb54db0878d5e79a6e1fdca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f8f0d57db274d3281daa344b6b628e2",
            "placeholder": "​",
            "style": "IPY_MODEL_67ea083248d74551a4bd99ec1885f119",
            "value": "100%"
          }
        },
        "815507206c9d48b09655ad50ed4d0a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1a083f3be284b4aa2874f06870d7a7d",
            "max": 574673361,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62be2dbb21464674a0189e7091f0b465",
            "value": 574673361
          }
        },
        "ae6ab078c3784961829fe8902c3b84d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7569c4672bc4979916eb2b65970d5af",
            "placeholder": "​",
            "style": "IPY_MODEL_ebe8fb7164824f9f8ad03749eac2e352",
            "value": " 548M/548M [00:39&lt;00:00, 15.3MB/s]"
          }
        },
        "8bbebff1a38140f29249d6ec768b9043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8f0d57db274d3281daa344b6b628e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ea083248d74551a4bd99ec1885f119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1a083f3be284b4aa2874f06870d7a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62be2dbb21464674a0189e7091f0b465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7569c4672bc4979916eb2b65970d5af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe8fb7164824f9f8ad03749eac2e352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}